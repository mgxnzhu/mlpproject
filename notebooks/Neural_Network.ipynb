{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "\n",
    "n_input = 28\n",
    "n_classes = 2\n",
    "learning_rate = 0.0001\n",
    "num_steps = 500\n",
    "batch_size = 100\n",
    "display_step = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slicedata(data, dataset):\n",
    "    trainset = data[dataset]\n",
    "    features = np.float32(trainset[:,1:-2])\n",
    "    labels_int = np.int32(trainset[:,-1])\n",
    "    labels = np.zeros((labels_int.shape[0], n_classes))\n",
    "    labels[range(labels_int.shape[0]), labels_int] = 1\n",
    "    return features, labels\n",
    "    \n",
    "with np.load(DATA_DIR+\"ccdataset.npz\") as data:\n",
    "    features, labels = slicedata(data, 'train')\n",
    "    features_valid, labels_valid = slicedata(data, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assume that each row of `features` corresponds to the same row as `labels`.\n",
    "assert features.shape[0] == labels.shape[0]\n",
    "\n",
    "features_placeholder = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels_placeholder = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "dataset = dataset.batch(batch_size)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "X, Y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelname = \"l4_u125\"\n",
    "def Baseline_model(x, n_classes, reuse, is_training):\n",
    "    with tf.variable_scope('Baseline', reuse=reuse):\n",
    "        layer1 = tf.layers.dense(inputs=x, units=125, activation=tf.nn.leaky_relu)\n",
    "        layer2 = tf.layers.dense(inputs=layer1, units=125, activation=tf.nn.leaky_relu)\n",
    "        layer3 = tf.layers.dense(inputs=layer2, units=125, activation=tf.nn.leaky_relu)\n",
    "        layer4 = tf.layers.dense(inputs=layer3, units=125, activation=tf.nn.leaky_relu)\n",
    "        #layer5 = tf.layers.dense(inputs=layer4, units=150, activation=tf.nn.leaky_relu)\n",
    "        out = tf.layers.dense(inputs=layer4, units=n_classes)\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-4f41ba74c260>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits_train = Baseline_model(X, n_classes, reuse=False, is_training=True)\n",
    "logits_test = Baseline_model(X, n_classes, reuse=True, is_training=False)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits_train, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "def modeleval(logits, Y):\n",
    "    predicted = tf.argmax(logits, 1)\n",
    "    actual = tf.argmax(Y, 1)\n",
    "\n",
    "    tp = tf.count_nonzero(predicted * actual)\n",
    "    tn = tf.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    fp = tf.count_nonzero(predicted * (actual - 1))\n",
    "    fn = tf.count_nonzero((predicted - 1) * actual)\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    fmeasure = (2 * precision * recall) / (precision + recall + 1e-8)\n",
    "    \n",
    "    return accuracy, fmeasure\n",
    "\n",
    "accuracy, fmeasure = modeleval(logits_test, Y)\n",
    "\n",
    "_features_valid = tf.placeholder(tf.float32, [None, n_input])\n",
    "_labels_valid = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "logits_val = Baseline_model(_features_valid, n_classes, reuse=True, is_training=True)\n",
    "logits_val_test = Baseline_model(_features_valid, n_classes, reuse=True, is_training=False)\n",
    "loss_val_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits_val, labels=_labels_valid))\n",
    "acc_val_op, f1_val_op = modeleval(logits_val_test, _labels_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Train Loss= 0.5557, Train Acc= 0.610, Train F1= 0.748\n",
      "Step 1, Valid Loss= 0.7807, Valid Acc= 0.136, Valid F1= 0.004\n",
      "Step 100, Train Loss= 0.1546, Train Acc= 0.940, Train F1= 0.950\n",
      "Step 100, Valid Loss= 0.1788, Valid Acc= 0.997, Valid F1= 0.510\n",
      "Step 200, Train Loss= 0.0773, Train Acc= 0.970, Train F1= 0.971\n",
      "Step 200, Valid Loss= 0.0623, Valid Acc= 0.994, Valid F1= 0.344\n",
      "Step 300, Train Loss= 0.0787, Train Acc= 0.980, Train F1= 0.981\n",
      "Step 300, Valid Loss= 0.0390, Valid Acc= 0.994, Valid F1= 0.361\n",
      "Step 400, Train Loss= 0.0609, Train Acc= 0.960, Train F1= 0.967\n",
      "Step 400, Valid Loss= 0.0402, Valid Acc= 0.993, Valid F1= 0.317\n",
      "Step 500, Train Loss= 0.0158, Train Acc= 1.000, Train F1= 1.000\n",
      "Step 500, Valid Loss= 0.0378, Valid Acc= 0.992, Valid F1= 0.296\n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: features, \\\n",
    "                                          labels_placeholder: labels})\n",
    "\n",
    "for step in range(1, num_steps + 1):\n",
    "    try:\n",
    "        sess.run(train_op)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        sess.run(iterator.initializer, feed_dict={features_placeholder: features, labels_placeholder: labels})\n",
    "        sess.run(train_op)\n",
    "\n",
    "    loss, acc, f1 = sess.run([loss_op, accuracy, fmeasure])\n",
    "    \n",
    "    loss_val, acc_val, f1_val = sess.run([loss_val_op, acc_val_op, f1_val_op], \\\n",
    "                                         feed_dict={_features_valid: features_valid, \\ \n",
    "                                                    _labels_valid: labels_valid})\n",
    "\n",
    "    stats.append([loss, acc, f1, loss_val, acc_val, f1_val])\n",
    "\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        print(\"Step \" + str(step) + \", Train Loss= \" + \\\n",
    "              \"{:.4f}\".format(loss) + \", Train Acc= \" + \\\n",
    "              \"{:.3f}\".format(acc)+ \", Train F1= \" + \\\n",
    "              \"{:.3f}\".format(f1) + \", Valid Loss= \" + \\\n",
    "              \"{:.4f}\".format(loss_val) + \", Valid Acc= \" + \\\n",
    "              \"{:.3f}\".format(acc_val)+ \", Valid F1= \" + \\\n",
    "              \"{:.3f}\".format(f1_val))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.array(stats)\n",
    "np.save(modelname+\".npy\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
